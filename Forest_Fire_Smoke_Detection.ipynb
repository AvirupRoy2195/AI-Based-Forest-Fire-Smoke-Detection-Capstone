{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "header-cell",
            "metadata": {},
            "source": [
                "# ðŸ”¥ AI-Based Forest Fire & Smoke Detection\n",
                "\n",
                "---\n",
                "\n",
                "## Project Overview\n",
                "\n",
                "This notebook implements an **end-to-end machine learning pipeline** for forest fire and smoke detection from aerial imagery. The pipeline covers:\n",
                "\n",
                "1. **Data Loading & EDA** - Statistical analysis and data understanding\n",
                "2. **Feature Engineering** - Domain-specific feature creation\n",
                "3. **Feature Selection** - Multiple selection methods\n",
                "4. **Model Development** - Multi-model comparison\n",
                "5. **Hyperparameter Tuning** - Optimization with cross-validation\n",
                "6. **Model Interpretability** - SHAP-based explanations\n",
                "7. **Spatial Analysis** - Risk heatmap visualization\n",
                "\n",
                "**Author:** Avirup Roy  \n",
                "**Date:** January 2026  \n",
                "**Version:** 1.0.0\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "imports-header",
            "metadata": {},
            "source": [
                "## 1. Environment Setup & Imports\n",
                "\n",
                "Import all required libraries and set reproducibility seeds."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "imports-cell",
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# IMPORTS & CONFIGURATION\n",
                "# =============================================================================\n",
                "\n",
                "# Standard Library\n",
                "import random\n",
                "import sys\n",
                "import json\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# Data Manipulation\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from scipy import stats\n",
                "from scipy.stats import ttest_ind, mannwhitneyu, shapiro\n",
                "\n",
                "# Machine Learning\n",
                "import sklearn\n",
                "from sklearn.model_selection import (\n",
                "    train_test_split, StratifiedKFold, cross_val_score,\n",
                "    cross_validate, GridSearchCV, RandomizedSearchCV\n",
                ")\n",
                "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
                "from sklearn.ensemble import (\n",
                "    RandomForestClassifier, GradientBoostingClassifier,\n",
                "    AdaBoostClassifier, IsolationForest\n",
                ")\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.svm import SVC\n",
                "from sklearn.naive_bayes import GaussianNB\n",
                "from sklearn.tree import DecisionTreeClassifier\n",
                "from xgboost import XGBClassifier\n",
                "from lightgbm import LGBMClassifier\n",
                "\n",
                "# Evaluation Metrics\n",
                "from sklearn.metrics import (\n",
                "    accuracy_score, precision_score, recall_score, f1_score,\n",
                "    confusion_matrix, classification_report, roc_auc_score,\n",
                "    roc_curve, precision_recall_curve, matthews_corrcoef,\n",
                "    average_precision_score, cohen_kappa_score,\n",
                "    balanced_accuracy_score, log_loss\n",
                ")\n",
                "from sklearn.inspection import permutation_importance\n",
                "\n",
                "# Feature Selection\n",
                "from sklearn.feature_selection import (\n",
                "    SelectKBest, f_classif, mutual_info_classif,\n",
                "    RFE, SelectFromModel, VarianceThreshold, SequentialFeatureSelector\n",
                ")\n",
                "from sklearn.decomposition import PCA\n",
                "\n",
                "# Model Interpretability\n",
                "import shap\n",
                "\n",
                "# Visualization\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "# Model Persistence\n",
                "import joblib\n",
                "\n",
                "# Spatial Analysis\n",
                "from scipy.spatial import distance\n",
                "from sklearn.cluster import DBSCAN, KMeans\n",
                "\n",
                "# =============================================================================\n",
                "# REPRODUCIBILITY CONFIGURATION\n",
                "# =============================================================================\n",
                "SEED = 42\n",
                "random.seed(SEED)\n",
                "np.random.seed(SEED)\n",
                "\n",
                "# Display settings\n",
                "pd.set_option('display.max_columns', 50)\n",
                "plt.style.use('seaborn-v0_8-whitegrid')\n",
                "\n",
                "# Version info\n",
                "print(\"=\" * 50)\n",
                "print(\"ENVIRONMENT INFORMATION\")\n",
                "print(\"=\" * 50)\n",
                "print(f\"Python version: {sys.version.split()[0]}\")\n",
                "print(f\"NumPy version: {np.__version__}\")\n",
                "print(f\"Pandas version: {pd.__version__}\")\n",
                "print(f\"Scikit-learn version: {sklearn.__version__}\")\n",
                "print(f\"Random Seed: {SEED}\")\n",
                "print(\"=\" * 50)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "data-loading-header",
            "metadata": {},
            "source": [
                "## 2. Data Loading & Initial EDA\n",
                "\n",
                "Load the dataset and perform initial exploratory analysis."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "data-loading-cell",
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# DATA LOADING\n",
                "# =============================================================================\n",
                "\n",
                "DATA_PATH = 'Forest Fire Smoke Dataset.xlsx'\n",
                "\n",
                "try:\n",
                "    df = pd.read_excel(DATA_PATH)\n",
                "    print(f\"âœ… Dataset loaded successfully: {DATA_PATH}\")\n",
                "except FileNotFoundError:\n",
                "    raise FileNotFoundError(f\"Dataset not found at {DATA_PATH}\")\n",
                "\n",
                "# Dataset Overview\n",
                "print(\"\\n\" + \"=\" * 50)\n",
                "print(\"DATASET OVERVIEW\")\n",
                "print(\"=\" * 50)\n",
                "print(f\"Shape: {df.shape[0]} rows Ã— {df.shape[1]} columns\")\n",
                "print(f\"\\nColumn Names:\\n{df.columns.tolist()}\")\n",
                "print(f\"\\nData Types:\\n{df.dtypes}\")\n",
                "print(f\"\\nMissing Values:\\n{df.isnull().sum()[df.isnull().sum() > 0]}\")\n",
                "\n",
                "# Target Distribution\n",
                "print(\"\\n\" + \"=\" * 50)\n",
                "print(\"TARGET DISTRIBUTION\")\n",
                "print(\"=\" * 50)\n",
                "target_dist = df['fire_label'].value_counts(normalize=True) * 100\n",
                "print(f\"Class 0 (No Fire): {target_dist[0]:.2f}%\")\n",
                "print(f\"Class 1 (Fire):    {target_dist[1]:.2f}%\")\n",
                "\n",
                "# Display first rows\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "descriptive-stats",
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# DESCRIPTIVE STATISTICS\n",
                "# =============================================================================\n",
                "\n",
                "print(\"DESCRIPTIVE STATISTICS\")\n",
                "print(\"=\" * 50)\n",
                "df.describe().T"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "statistical-analysis-header",
            "metadata": {},
            "source": [
                "## 3. Statistical Analysis\n",
                "\n",
                "Perform normality tests and statistical significance tests for features."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "statistical-analysis-cell",
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# STATISTICAL ANALYSIS\n",
                "# =============================================================================\n",
                "\n",
                "continuous_features = df.columns.drop('fire_label').tolist()\n",
                "\n",
                "def test_normality(data, feature_name):\n",
                "    \"\"\"Test normality using Shapiro-Wilk test.\"\"\"\n",
                "    sample = data.sample(min(5000, len(data)), random_state=SEED)\n",
                "    stat, p_value = shapiro(sample)\n",
                "    is_normal = p_value > 0.05\n",
                "    return {'feature': feature_name, 'p_value': p_value, 'is_normal': is_normal}\n",
                "\n",
                "# Normality Tests (first 5 features)\n",
                "print(\"NORMALITY TESTS (Shapiro-Wilk)\")\n",
                "print(\"=\" * 50)\n",
                "normality_results = [test_normality(df[col], col) for col in continuous_features[:5]]\n",
                "print(pd.DataFrame(normality_results))\n",
                "\n",
                "# Feature Significance Tests\n",
                "print(\"\\nFEATURE SIGNIFICANCE TESTS\")\n",
                "print(\"=\" * 50)\n",
                "results_sig = []\n",
                "for col in continuous_features:\n",
                "    fire_samples = df[df['fire_label'] == 1][col]\n",
                "    no_fire_samples = df[df['fire_label'] == 0][col]\n",
                "    \n",
                "    _, p_t = ttest_ind(fire_samples, no_fire_samples)\n",
                "    _, p_mw = mannwhitneyu(fire_samples, no_fire_samples, alternative='two-sided')\n",
                "    \n",
                "    results_sig.append({\n",
                "        'Feature': col,\n",
                "        'T-Test p': round(p_t, 6),\n",
                "        'Mann-Whitney p': round(p_mw, 6),\n",
                "        'Significant': p_mw < 0.05\n",
                "    })\n",
                "\n",
                "sig_df = pd.DataFrame(results_sig)\n",
                "print(f\"\\nSignificant features (p < 0.05): {sig_df['Significant'].sum()} / {len(sig_df)}\")\n",
                "sig_df"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "outlier-header",
            "metadata": {},
            "source": [
                "## 4. Outlier Detection"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "outlier-cell",
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# OUTLIER DETECTION\n",
                "# =============================================================================\n",
                "\n",
                "def detect_outliers_iqr(df, column):\n",
                "    \"\"\"Detect outliers using IQR method.\"\"\"\n",
                "    Q1 = df[column].quantile(0.25)\n",
                "    Q3 = df[column].quantile(0.75)\n",
                "    IQR = Q3 - Q1\n",
                "    lower_bound = Q1 - 1.5 * IQR\n",
                "    upper_bound = Q3 + 1.5 * IQR\n",
                "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
                "    return len(outliers), lower_bound, upper_bound\n",
                "\n",
                "print(\"OUTLIER DETECTION (IQR Method)\")\n",
                "print(\"=\" * 50)\n",
                "outlier_summary = []\n",
                "for col in continuous_features[:5]:\n",
                "    count, lower, upper = detect_outliers_iqr(df, col)\n",
                "    outlier_summary.append({'Feature': col, 'Outliers': count, 'Lower': round(lower, 2), 'Upper': round(upper, 2)})\n",
                "\n",
                "pd.DataFrame(outlier_summary)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "feature-eng-header",
            "metadata": {},
            "source": [
                "## 5. Feature Engineering\n",
                "\n",
                "Create domain-specific features for fire detection."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "feature-eng-cell",
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# FEATURE ENGINEERING\n",
                "# =============================================================================\n",
                "\n",
                "print(\"FEATURE ENGINEERING\")\n",
                "print(\"=\" * 50)\n",
                "original_features = df.shape[1]\n",
                "\n",
                "# 1. Spectral Ratios\n",
                "df['red_green_ratio'] = df['mean_red'] / (df['mean_green'] + 1e-10)\n",
                "df['red_blue_ratio_calc'] = df['mean_red'] / (df['mean_blue'] + 1e-10)\n",
                "print(\"âœ… Created spectral ratio features\")\n",
                "\n",
                "# 2. Texture Aggregations\n",
                "color_cols = ['mean_red', 'mean_green', 'mean_blue']\n",
                "df['color_mean'] = df[color_cols].mean(axis=1)\n",
                "df['color_std'] = df[color_cols].std(axis=1)\n",
                "print(\"âœ… Created texture aggregation features\")\n",
                "\n",
                "# 3. Log Transformation\n",
                "if 'intensity_std' in df.columns:\n",
                "    df['log_intensity_std'] = np.log1p(df['intensity_std'])\n",
                "    print(\"âœ… Created log-transformed features\")\n",
                "\n",
                "# 4. Spatial Coordinates (for demonstration)\n",
                "if 'x_coord' not in df.columns:\n",
                "    df['x_coord'] = np.random.randint(0, 1000, size=len(df))\n",
                "    df['y_coord'] = np.random.randint(0, 1000, size=len(df))\n",
                "    print(\"âœ… Added simulated spatial coordinates\")\n",
                "\n",
                "print(f\"\\nFeatures: {original_features} â†’ {df.shape[1]} (+{df.shape[1] - original_features} new)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "feature-sel-header",
            "metadata": {},
            "source": [
                "## 6. Feature Selection"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "feature-sel-cell",
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# FEATURE SELECTION\n",
                "# =============================================================================\n",
                "\n",
                "X = df.drop('fire_label', axis=1)\n",
                "y = df['fire_label']\n",
                "\n",
                "print(\"FEATURE SELECTION\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "# 1. Variance Threshold\n",
                "selector_vt = VarianceThreshold(threshold=0.01)\n",
                "X_vt = selector_vt.fit_transform(X)\n",
                "print(f\"After VarianceThreshold: {X_vt.shape[1]} features\")\n",
                "\n",
                "# 2. SelectKBest\n",
                "k_best = min(10, X.shape[1])\n",
                "selector_kb = SelectKBest(score_func=f_classif, k=k_best)\n",
                "X_kb = selector_kb.fit_transform(X, y)\n",
                "selected_features_kb = X.columns[selector_kb.get_support()].tolist()\n",
                "print(f\"\\nTop {k_best} features via SelectKBest:\")\n",
                "print(selected_features_kb)\n",
                "\n",
                "# 3. RFE\n",
                "rf_estimator = RandomForestClassifier(n_estimators=50, random_state=SEED, n_jobs=-1)\n",
                "n_rfe = min(8, X.shape[1])\n",
                "selector_rfe = RFE(estimator=rf_estimator, n_features_to_select=n_rfe, step=1)\n",
                "selector_rfe.fit(X, y)\n",
                "selected_features_rfe = X.columns[selector_rfe.support_].tolist()\n",
                "print(f\"\\nTop {n_rfe} features via RFE:\")\n",
                "print(selected_features_rfe)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "model-header",
            "metadata": {},
            "source": [
                "## 7. Model Development & Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "model-cell",
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# MODEL DEVELOPMENT\n",
                "# =============================================================================\n",
                "\n",
                "print(\"MODEL DEVELOPMENT\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "# Train-Test Split\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X, y, test_size=0.2, stratify=y, random_state=SEED\n",
                ")\n",
                "print(f\"Train set: {X_train.shape[0]} samples\")\n",
                "print(f\"Test set:  {X_test.shape[0]} samples\")\n",
                "\n",
                "# Scaling\n",
                "scaler = StandardScaler()\n",
                "X_train_scaled = scaler.fit_transform(X_train)\n",
                "X_test_scaled = scaler.transform(X_test)\n",
                "\n",
                "# Model Comparison\n",
                "models = {\n",
                "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=SEED),\n",
                "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=SEED, n_jobs=-1),\n",
                "    'XGBoost': XGBClassifier(n_estimators=100, random_state=SEED, eval_metric='logloss', verbosity=0),\n",
                "    'LightGBM': LGBMClassifier(n_estimators=100, random_state=SEED, verbose=-1)\n",
                "}\n",
                "\n",
                "results = []\n",
                "for name, model in models.items():\n",
                "    model.fit(X_train_scaled, y_train)\n",
                "    y_pred = model.predict(X_test_scaled)\n",
                "    y_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
                "    \n",
                "    results.append({\n",
                "        'Model': name,\n",
                "        'Accuracy': round(accuracy_score(y_test, y_pred), 4),\n",
                "        'Precision': round(precision_score(y_test, y_pred), 4),\n",
                "        'Recall': round(recall_score(y_test, y_pred), 4),\n",
                "        'F1-Score': round(f1_score(y_test, y_pred), 4),\n",
                "        'ROC-AUC': round(roc_auc_score(y_test, y_prob), 4)\n",
                "    })\n",
                "\n",
                "results_df = pd.DataFrame(results).sort_values('F1-Score', ascending=False)\n",
                "print(\"\\nMODEL COMPARISON RESULTS\")\n",
                "print(\"=\" * 50)\n",
                "results_df"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "tuning-header",
            "metadata": {},
            "source": [
                "## 8. Hyperparameter Tuning"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "tuning-cell",
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# HYPERPARAMETER TUNING\n",
                "# =============================================================================\n",
                "\n",
                "print(\"HYPERPARAMETER TUNING (XGBoost)\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "param_dist = {\n",
                "    'n_estimators': [100, 200],\n",
                "    'max_depth': [3, 6, 9],\n",
                "    'learning_rate': [0.01, 0.1, 0.2]\n",
                "}\n",
                "\n",
                "random_search = RandomizedSearchCV(\n",
                "    XGBClassifier(random_state=SEED, eval_metric='logloss', verbosity=0),\n",
                "    param_distributions=param_dist,\n",
                "    n_iter=5,\n",
                "    cv=3,\n",
                "    scoring='f1',\n",
                "    random_state=SEED,\n",
                "    n_jobs=-1\n",
                ")\n",
                "random_search.fit(X_train_scaled, y_train)\n",
                "best_xgb = random_search.best_estimator_\n",
                "\n",
                "print(f\"Best Parameters: {random_search.best_params_}\")\n",
                "print(f\"Best F1-Score (CV): {random_search.best_score_:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "shap-header",
            "metadata": {},
            "source": [
                "## 9. Model Interpretability (SHAP)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "shap-cell",
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# MODEL INTERPRETABILITY\n",
                "# =============================================================================\n",
                "\n",
                "print(\"SHAP ANALYSIS\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "rf_model = models['Random Forest']\n",
                "explainer = shap.TreeExplainer(rf_model)\n",
                "shap_values = explainer.shap_values(X_test_scaled)\n",
                "\n",
                "print(\"Generating SHAP Summary Plot...\")\n",
                "plt.figure(figsize=(12, 8))\n",
                "shap.summary_plot(shap_values[1], X_test, feature_names=X.columns.tolist(), show=False)\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "print(\"âœ… SHAP analysis complete\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "spatial-header",
            "metadata": {},
            "source": [
                "## 10. Spatial Analysis & Risk Heatmap"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "spatial-cell",
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# SPATIAL ANALYSIS\n",
                "# =============================================================================\n",
                "\n",
                "print(\"SPATIAL RISK ANALYSIS\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "def aggregate_predictions_by_grid(df, probabilities, grid_size=100):\n",
                "    \"\"\"Aggregate predictions spatially into grid cells.\"\"\"\n",
                "    df_copy = df.copy()\n",
                "    df_copy['risk_score'] = probabilities\n",
                "    df_copy['grid_x'] = (df_copy['x_coord'] // grid_size).astype(int)\n",
                "    df_copy['grid_y'] = (df_copy['y_coord'] // grid_size).astype(int)\n",
                "    \n",
                "    grid_agg = df_copy.groupby(['grid_x', 'grid_y']).agg({\n",
                "        'risk_score': ['mean', 'max', 'count']\n",
                "    }).reset_index()\n",
                "    grid_agg.columns = ['grid_x', 'grid_y', 'avg_risk', 'max_risk', 'tile_count']\n",
                "    return grid_agg\n",
                "\n",
                "best_model = models['Random Forest']\n",
                "all_probs = best_model.predict_proba(scaler.transform(X))[:, 1]\n",
                "grid_data = aggregate_predictions_by_grid(df, all_probs)\n",
                "\n",
                "# Heatmap\n",
                "plt.figure(figsize=(12, 10))\n",
                "pivot_table = grid_data.pivot(index='grid_y', columns='grid_x', values='avg_risk')\n",
                "sns.heatmap(pivot_table, cmap='YlOrRd', cbar_kws={'label': 'Fire Risk Score'})\n",
                "plt.title('Forest Fire Risk Heatmap', fontsize=14, fontweight='bold')\n",
                "plt.xlabel('Grid X')\n",
                "plt.ylabel('Grid Y')\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "print(\"âœ… Risk heatmap generated\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "export-header",
            "metadata": {},
            "source": [
                "## 11. Model Export & Reproducibility"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "export-cell",
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# MODEL EXPORT\n",
                "# =============================================================================\n",
                "\n",
                "print(\"MODEL EXPORT\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "# Save model\n",
                "joblib.dump(best_model, 'fire_detection_model.pkl')\n",
                "joblib.dump(scaler, 'feature_scaler.pkl')\n",
                "print(\"âœ… Model saved: fire_detection_model.pkl\")\n",
                "print(\"âœ… Scaler saved: feature_scaler.pkl\")\n",
                "\n",
                "# Save configuration\n",
                "model_config = {\n",
                "    'model_type': 'RandomForestClassifier',\n",
                "    'features_used': X.columns.tolist(),\n",
                "    'random_state': SEED,\n",
                "    'scaler': 'StandardScaler',\n",
                "    'train_samples': len(X_train),\n",
                "    'test_samples': len(X_test)\n",
                "}\n",
                "\n",
                "with open('model_config.json', 'w') as f:\n",
                "    json.dump(model_config, f, indent=4)\n",
                "print(\"âœ… Configuration saved: model_config.json\")\n",
                "\n",
                "print(\"\\n\" + \"=\" * 50)\n",
                "print(\"PIPELINE COMPLETE!\")\n",
                "print(\"=\" * 50)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.9.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}