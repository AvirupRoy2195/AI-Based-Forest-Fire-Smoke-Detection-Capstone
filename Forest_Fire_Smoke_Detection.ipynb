{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üî• AI-Based Forest Fire & Smoke Detection\n",
                "**Author:** Avirup Roy | **Version:** 3.0 | **Date:** February 2026\n",
                "\n",
                "---\n",
                "## Pipeline Overview\n",
                "1. Data Loading & EDA\n",
                "2. Statistical Analysis & Multicollinearity (VIF)\n",
                "3. Feature Engineering & Selection\n",
                "4. **Dual Approach:** Anomaly Detection (No SMOTE) vs Classifiers (With SMOTE)\n",
                "5. Cross-Validation & Hyperparameter Tuning\n",
                "6. Model Comparison & Export"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === IMPORTS ===\n",
                "import warnings; warnings.filterwarnings('ignore')\n",
                "import random, sys, json\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from scipy import stats\n",
                "from scipy.stats import ttest_ind, mannwhitneyu, multivariate_normal\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import joblib\n",
                "\n",
                "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate, RandomizedSearchCV\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier,\n",
                "    ExtraTreesClassifier, IsolationForest)\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.svm import SVC, OneClassSVM\n",
                "from sklearn.covariance import EllipticEnvelope\n",
                "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
                "    average_precision_score, confusion_matrix, matthews_corrcoef, roc_curve, precision_recall_curve)\n",
                "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif, RFE, VarianceThreshold\n",
                "\n",
                "# Optional\n",
                "try: from xgboost import XGBClassifier\n",
                "except: XGBClassifier = None\n",
                "try: from lightgbm import LGBMClassifier\n",
                "except: LGBMClassifier = None\n",
                "try: from imblearn.over_sampling import SMOTE; SMOTE_OK = True\n",
                "except: SMOTE_OK = False\n",
                "try: from statsmodels.stats.outliers_influence import variance_inflation_factor; VIF_OK = True\n",
                "except: VIF_OK = False\n",
                "\n",
                "SEED = 42; random.seed(SEED); np.random.seed(SEED)\n",
                "print(f\"‚úÖ Environment Ready | SMOTE: {SMOTE_OK} | VIF: {VIF_OK}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Data Loading & EDA"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.read_excel('Forest Fire Smoke Dataset.xlsx')\n",
                "print(f\"Dataset: {df.shape[0]} rows √ó {df.shape[1]} cols\")\n",
                "class_counts = df['fire_label'].value_counts()\n",
                "imbalance_ratio = class_counts[0] / class_counts[1]\n",
                "print(f\"Class 0: {class_counts[0]} | Class 1: {class_counts[1]} | Ratio: {imbalance_ratio:.2f}:1\")\n",
                "\n",
                "# Descriptive Stats\n",
                "desc = df.describe().T\n",
                "desc['skew'], desc['kurt'] = df.skew(), df.kurtosis()\n",
                "desc"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Distributions\n",
                "fig, axes = plt.subplots(2, 5, figsize=(16, 6))\n",
                "for i, col in enumerate(df.columns.drop('fire_label')[:10]):\n",
                "    ax = axes.flatten()[i]\n",
                "    sns.histplot(data=df, x=col, hue='fire_label', kde=True, ax=ax, palette='coolwarm')\n",
                "    ax.set_title(col, fontsize=9)\n",
                "plt.tight_layout(); plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Correlation & Multicollinearity"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(10, 8))\n",
                "sns.heatmap(df.corr(), annot=True, fmt='.2f', cmap='RdBu_r', center=0, mask=np.triu(np.ones_like(df.corr(), dtype=bool)))\n",
                "plt.title('Correlation Matrix'); plt.tight_layout(); plt.show()\n",
                "\n",
                "# VIF\n",
                "if VIF_OK:\n",
                "    X_vif = StandardScaler().fit_transform(df.drop('fire_label', axis=1))\n",
                "    vif = pd.DataFrame({'Feature': df.columns.drop('fire_label'), 'VIF': [variance_inflation_factor(X_vif, i) for i in range(X_vif.shape[1])]})\n",
                "    print(vif.sort_values('VIF', ascending=False).to_string(index=False))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Statistical Tests & Feature Engineering"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Significance Tests\n",
                "sig_results = []\n",
                "for col in df.columns.drop('fire_label'):\n",
                "    fire, no_fire = df[df['fire_label']==1][col], df[df['fire_label']==0][col]\n",
                "    _, p = mannwhitneyu(fire, no_fire)\n",
                "    d = (fire.mean() - no_fire.mean()) / np.sqrt(((len(fire)-1)*fire.std()**2 + (len(no_fire)-1)*no_fire.std()**2) / (len(fire)+len(no_fire)-2))\n",
                "    sig_results.append({'Feature': col, 'p-value': round(p, 6), 'Cohen_d': round(d, 3), 'Sig': p < 0.05})\n",
                "sig_df = pd.DataFrame(sig_results).sort_values('Cohen_d', key=abs, ascending=False)\n",
                "print(f\"Significant features: {sig_df['Sig'].sum()}/{len(sig_df)}\")\n",
                "sig_df.head(10)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Feature Engineering\n",
                "orig = df.shape[1]\n",
                "df['red_green_ratio'] = df['mean_red'] / (df['mean_green'] + 1e-10)\n",
                "df['red_blue_calc'] = df['mean_red'] / (df['mean_blue'] + 1e-10)\n",
                "df['color_mean'] = df[['mean_red', 'mean_green', 'mean_blue']].mean(axis=1)\n",
                "df['color_std'] = df[['mean_red', 'mean_green', 'mean_blue']].std(axis=1)\n",
                "if 'intensity_std' in df.columns: df['log_intensity'] = np.log1p(df['intensity_std'].clip(0))\n",
                "if 'hot_pixel_fraction' in df.columns: df['log_hotpixel'] = np.log1p(df['hot_pixel_fraction'])\n",
                "df['x_coord'] = np.random.randint(0, 1000, len(df))\n",
                "df['y_coord'] = np.random.randint(0, 1000, len(df))\n",
                "print(f\"Features: {orig} ‚Üí {df.shape[1]} (+{df.shape[1]-orig})\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Feature Selection & Data Prep"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X, y = df.drop('fire_label', axis=1), df['fire_label']\n",
                "\n",
                "# SelectKBest\n",
                "kb = SelectKBest(f_classif, k=min(12, X.shape[1])).fit(X, y)\n",
                "print(\"Top features (F-score):\")\n",
                "print(pd.DataFrame({'Feature': X.columns, 'Score': kb.scores_}).sort_values('Score', ascending=False).head(10).to_string(index=False))\n",
                "\n",
                "# Train-Test Split\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=SEED)\n",
                "scaler = StandardScaler()\n",
                "X_train_sc, X_test_sc = scaler.fit_transform(X_train), scaler.transform(X_test)\n",
                "print(f\"\\nTrain: {len(y_train)} | Test: {len(y_test)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5A. Approach A: Anomaly Detection (No SMOTE)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 50)\n",
                "print(\"APPROACH A: ANOMALY DETECTION\")\n",
                "print(\"=\" * 50)\n",
                "X_normal = X_train_sc[y_train == 0]\n",
                "contam = y_train.mean()\n",
                "\n",
                "anomaly_models = {\n",
                "    'Elliptic Envelope': EllipticEnvelope(contamination=contam, random_state=SEED),\n",
                "    'Isolation Forest': IsolationForest(contamination=contam, random_state=SEED, n_jobs=-1),\n",
                "    'One-Class SVM': OneClassSVM(nu=contam, kernel='rbf')\n",
                "}\n",
                "\n",
                "anomaly_results = []\n",
                "for name, model in anomaly_models.items():\n",
                "    model.fit(X_normal)\n",
                "    pred = np.where(model.predict(X_test_sc) == -1, 1, 0)\n",
                "    anomaly_results.append({'Model': name, 'Acc': round(accuracy_score(y_test, pred), 4),\n",
                "        'Prec': round(precision_score(y_test, pred), 4), 'Recall': round(recall_score(y_test, pred), 4),\n",
                "        'F1': round(f1_score(y_test, pred), 4), 'MCC': round(matthews_corrcoef(y_test, pred), 4)})\n",
                "\n",
                "anomaly_df = pd.DataFrame(anomaly_results).sort_values('F1', ascending=False)\n",
                "anomaly_df"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5B. Approach B: Classifiers (With SMOTE)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 50)\n",
                "print(\"APPROACH B: SMOTE + CLASSIFIERS\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "if SMOTE_OK:\n",
                "    X_sm, y_sm = SMOTE(random_state=SEED).fit_resample(X_train_sc, y_train)\n",
                "    print(f\"SMOTE: {np.bincount(y_train)} ‚Üí {np.bincount(y_sm)}\")\n",
                "else:\n",
                "    X_sm, y_sm = X_train_sc, y_train\n",
                "\n",
                "models = {\n",
                "    'Logistic': LogisticRegression(max_iter=1000, class_weight='balanced', random_state=SEED),\n",
                "    'Random Forest': RandomForestClassifier(100, class_weight='balanced', random_state=SEED, n_jobs=-1),\n",
                "    'Gradient Boost': GradientBoostingClassifier(100, random_state=SEED),\n",
                "    'AdaBoost': AdaBoostClassifier(100, random_state=SEED),\n",
                "    'ExtraTrees': ExtraTreesClassifier(100, class_weight='balanced', random_state=SEED, n_jobs=-1),\n",
                "    'SVM': SVC(probability=True, class_weight='balanced', random_state=SEED)\n",
                "}\n",
                "if XGBClassifier: models['XGBoost'] = XGBClassifier(100, scale_pos_weight=imbalance_ratio, random_state=SEED, verbosity=0)\n",
                "if LGBMClassifier: models['LightGBM'] = LGBMClassifier(100, class_weight='balanced', random_state=SEED, verbose=-1)\n",
                "\n",
                "results, trained = [], {}\n",
                "for name, model in models.items():\n",
                "    model.fit(X_sm, y_sm); trained[name] = model\n",
                "    pred = model.predict(X_test_sc)\n",
                "    prob = model.predict_proba(X_test_sc)[:, 1] if hasattr(model, 'predict_proba') else None\n",
                "    results.append({'Model': name, 'Acc': round(accuracy_score(y_test, pred), 4),\n",
                "        'Prec': round(precision_score(y_test, pred), 4), 'Recall': round(recall_score(y_test, pred), 4),\n",
                "        'F1': round(f1_score(y_test, pred), 4), 'ROC-AUC': round(roc_auc_score(y_test, prob), 4) if prob is not None else None,\n",
                "        'PR-AUC': round(average_precision_score(y_test, prob), 4) if prob is not None else None})\n",
                "\n",
                "results_df = pd.DataFrame(results).sort_values('F1', ascending=False)\n",
                "results_df"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Hyperparameter Tuning"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Tune Random Forest\n",
                "rf_search = RandomizedSearchCV(\n",
                "    RandomForestClassifier(class_weight='balanced', random_state=SEED, n_jobs=-1),\n",
                "    {'n_estimators': [100, 200], 'max_depth': [10, 20, None], 'min_samples_split': [2, 5]},\n",
                "    n_iter=8, cv=3, scoring='f1', random_state=SEED, n_jobs=-1\n",
                ")\n",
                "rf_search.fit(X_sm, y_sm)\n",
                "print(f\"Best RF: {rf_search.best_params_} | F1: {rf_search.best_score_:.4f}\")\n",
                "\n",
                "# Evaluate\n",
                "best_rf = rf_search.best_estimator_\n",
                "y_pred = best_rf.predict(X_test_sc)\n",
                "y_prob = best_rf.predict_proba(X_test_sc)[:, 1]\n",
                "print(f\"\\nTuned RF on Test: F1={f1_score(y_test, y_pred):.4f} | ROC-AUC={roc_auc_score(y_test, y_prob):.4f}\")\n",
                "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. ROC & PR Curves"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
                "for name, m in list(trained.items())[:5]:\n",
                "    if hasattr(m, 'predict_proba'):\n",
                "        prob = m.predict_proba(X_test_sc)[:, 1]\n",
                "        fpr, tpr, _ = roc_curve(y_test, prob)\n",
                "        axes[0].plot(fpr, tpr, label=f\"{name} ({roc_auc_score(y_test, prob):.3f})\")\n",
                "        prec, rec, _ = precision_recall_curve(y_test, prob)\n",
                "        axes[1].plot(rec, prec, label=f\"{name} ({average_precision_score(y_test, prob):.3f})\")\n",
                "axes[0].plot([0,1], [0,1], 'k--'); axes[0].set_title('ROC Curves'); axes[0].legend(fontsize=8)\n",
                "axes[1].set_title('PR Curves'); axes[1].legend(fontsize=8)\n",
                "plt.tight_layout(); plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Feature Importance & Comparison"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fi = pd.DataFrame({'Feature': X.columns, 'Importance': best_rf.feature_importances_}).sort_values('Importance', ascending=False)\n",
                "plt.figure(figsize=(8, 6))\n",
                "sns.barplot(data=fi.head(12), x='Importance', y='Feature', palette='viridis')\n",
                "plt.title('Feature Importance'); plt.tight_layout(); plt.show()\n",
                "\n",
                "# Compare approaches\n",
                "print(\"\\n\" + \"=\" * 50)\n",
                "best_a, best_b = anomaly_df.iloc[0], results_df.iloc[0]\n",
                "print(f\"Best Anomaly: {best_a['Model']} (F1={best_a['F1']})\")\n",
                "print(f\"Best Classifier: {best_b['Model']} (F1={best_b['F1']})\")\n",
                "final = best_b['Model'] if best_b['F1'] > best_a['F1'] else best_a['Model']\n",
                "print(f\"\\nüèÜ WINNER: {final}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Export"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "joblib.dump(best_rf, 'fire_detection_model.pkl')\n",
                "joblib.dump(scaler, 'feature_scaler.pkl')\n",
                "json.dump({'model': 'RandomForest', 'features': X.columns.tolist(), 'params': rf_search.best_params_}, open('model_config.json', 'w'), indent=2)\n",
                "print(\"‚úÖ Exported: fire_detection_model.pkl, feature_scaler.pkl, model_config.json\")\n",
                "print(\"\\n\" + \"=\" * 50 + \"\\nüéâ PIPELINE COMPLETE!\\n\" + \"=\" * 50)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}